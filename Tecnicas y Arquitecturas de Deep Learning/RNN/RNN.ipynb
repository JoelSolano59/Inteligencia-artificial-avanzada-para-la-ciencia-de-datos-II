{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#RNN\n",
        "**Joel Isaias Solano Ocampo | A01639289**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kyLZQ-vdneOF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm_K8mxlIJ95"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descarga de datos\n"
      ],
      "metadata": {
        "id": "joisJtvjId0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_fileDL = tf.keras.utils.get_file('pg90.txt', 'https://www.gutenberg.org/cache/epub/90/pg90.txt')\n",
        "\n",
        "text = open(path_to_fileDL, 'rb').read().decode(encoding='utf-8')\n",
        "print('Longitud del texto:    {} caracteres'.format(len(text)))\n",
        "\n",
        "vocab = sorted(set(text))\n",
        "print ('El texto esta compuesto de estos {} caracteres'.format(len(vocab)))\n",
        "print (vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDFHefm3IQV9",
        "outputId": "221cb7a8-5b48-4cba-ec9f-0a561bedfc5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.gutenberg.org/cache/epub/90/pg90.txt\n",
            "556635/556635 [==============================] - 1s 2us/step\n",
            "Longitud del texto:    550671 caracteres\n",
            "El texto esta compuesto de estos 91 caracteres\n",
            "['\\n', '\\r', ' ', '!', '#', '$', '%', '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'é', '—', '‘', '’', '“', '”', '•', '™', '\\ufeff']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tablas de traduccion o Inversa de vocabulario\n"
      ],
      "metadata": {
        "id": "Jdme2idzJ-AZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)"
      ],
      "metadata": {
        "id": "JEmxggHLKBTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for char,_ in zip(char2idx, range(len(vocab))):\n",
        "  print(' {:4s}: {:3d},'.format(repr(char), char2idx[char]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTPGhiRJKkjd",
        "outputId": "d36ce317-eb8e-430b-80a1-b53f42174070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " '\\n':   0,\n",
            " '\\r':   1,\n",
            " ' ' :   2,\n",
            " '!' :   3,\n",
            " '#' :   4,\n",
            " '$' :   5,\n",
            " '%' :   6,\n",
            " '(' :   7,\n",
            " ')' :   8,\n",
            " '*' :   9,\n",
            " ',' :  10,\n",
            " '-' :  11,\n",
            " '.' :  12,\n",
            " '/' :  13,\n",
            " '0' :  14,\n",
            " '1' :  15,\n",
            " '2' :  16,\n",
            " '3' :  17,\n",
            " '4' :  18,\n",
            " '5' :  19,\n",
            " '6' :  20,\n",
            " '7' :  21,\n",
            " '8' :  22,\n",
            " '9' :  23,\n",
            " ':' :  24,\n",
            " ';' :  25,\n",
            " '?' :  26,\n",
            " 'A' :  27,\n",
            " 'B' :  28,\n",
            " 'C' :  29,\n",
            " 'D' :  30,\n",
            " 'E' :  31,\n",
            " 'F' :  32,\n",
            " 'G' :  33,\n",
            " 'H' :  34,\n",
            " 'I' :  35,\n",
            " 'J' :  36,\n",
            " 'K' :  37,\n",
            " 'L' :  38,\n",
            " 'M' :  39,\n",
            " 'N' :  40,\n",
            " 'O' :  41,\n",
            " 'P' :  42,\n",
            " 'Q' :  43,\n",
            " 'R' :  44,\n",
            " 'S' :  45,\n",
            " 'T' :  46,\n",
            " 'U' :  47,\n",
            " 'V' :  48,\n",
            " 'W' :  49,\n",
            " 'X' :  50,\n",
            " 'Y' :  51,\n",
            " 'Z' :  52,\n",
            " '[' :  53,\n",
            " ']' :  54,\n",
            " '_' :  55,\n",
            " 'a' :  56,\n",
            " 'b' :  57,\n",
            " 'c' :  58,\n",
            " 'd' :  59,\n",
            " 'e' :  60,\n",
            " 'f' :  61,\n",
            " 'g' :  62,\n",
            " 'h' :  63,\n",
            " 'i' :  64,\n",
            " 'j' :  65,\n",
            " 'k' :  66,\n",
            " 'l' :  67,\n",
            " 'm' :  68,\n",
            " 'n' :  69,\n",
            " 'o' :  70,\n",
            " 'p' :  71,\n",
            " 'q' :  72,\n",
            " 'r' :  73,\n",
            " 's' :  74,\n",
            " 't' :  75,\n",
            " 'u' :  76,\n",
            " 'v' :  77,\n",
            " 'w' :  78,\n",
            " 'x' :  79,\n",
            " 'y' :  80,\n",
            " 'z' :  81,\n",
            " 'é' :  82,\n",
            " '—' :  83,\n",
            " '‘' :  84,\n",
            " '’' :  85,\n",
            " '“' :  86,\n",
            " '”' :  87,\n",
            " '•' :  88,\n",
            " '™' :  89,\n",
            " '\\ufeff':  90,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "convertir texto a enteros"
      ],
      "metadata": {
        "id": "A6LoNExkLJim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "metadata": {
        "id": "u5Uu91VXLLKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostramos algunos caracteres\n",
        "print('text: {}'.format(repr(text[:50])))\n",
        "print('{}'.format(repr(text_as_int[:50])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8N1RzNGLUXp",
        "outputId": "89330fec-86d8-47e7-d97a-77462c117ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text: '\\ufeffThe Project Gutenberg eBook of The Son of Tarzan\\r'\n",
            "array([90, 46, 63, 60,  2, 42, 73, 70, 65, 60, 58, 75,  2, 33, 76, 75, 60,\n",
            "       69, 57, 60, 73, 62,  2, 60, 28, 70, 70, 66,  2, 70, 61,  2, 46, 63,\n",
            "       60,  2, 45, 70, 69,  2, 70, 61,  2, 46, 56, 73, 81, 56, 69,  1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPARAR DATOS"
      ],
      "metadata": {
        "id": "jDdRMqTGL4es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "seq_length = 100\n",
        "\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "AqLVBIzRL5dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#comprobar datos\n",
        "for item in sequences.take(10):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAGJWcbgMexu",
        "outputId": "77e0d18a-c1c2-46c0-c476-2929ef32a33c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'\\ufeffThe Project Gutenberg eBook of The Son of Tarzan\\r\\n    \\r\\nThis ebook is for the use of anyone anywhere'\n",
            "' in the United States and\\r\\nmost other parts of the world at no cost and with almost no restrictions\\r\\n'\n",
            "'whatsoever. You may copy it, give it away or re-use it under the terms\\r\\nof the Project Gutenberg Lice'\n",
            "'nse included with this ebook or online\\r\\nat www.gutenberg.org. If you are not located in the United St'\n",
            "'ates,\\r\\nyou will have to check the laws of the country where you are located\\r\\nbefore using this eBook.'\n",
            "'\\r\\n\\r\\nTitle: The Son of Tarzan\\r\\n\\r\\n\\r\\nAuthor: Edgar Rice Burroughs\\r\\n\\r\\nRelease date: November 1, 1993 [eBo'\n",
            "'ok #90]\\r\\n                Most recently updated: June 23, 2022\\r\\n\\r\\nLanguage: English\\r\\n\\r\\n\\r\\n\\r\\n*** START O'\n",
            "'F THE PROJECT GUTENBERG EBOOK THE SON OF TARZAN ***\\r\\n[Illustration]\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nThe Son Of Tarzan\\r\\n\\r\\nby '\n",
            "'Edgar Rice Burroughs\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nTo Hulbert Burroughs\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nContents\\r\\n\\r\\n I.\\r\\n II.\\r\\n III.\\r\\n IV.\\r\\n V.\\r\\n'\n",
            "' VI.\\r\\n VII.\\r\\n VIII.\\r\\n IX.\\r\\n X.\\r\\n XI.\\r\\n XII.\\r\\n XIII.\\r\\n XIV.\\r\\n XV.\\r\\n XVI.\\r\\n XVII.\\r\\n XVIII.\\r\\n XIX.\\r\\n XX.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparar datos de entrenamiento  (Entrada 0 a 99 )  (Salida 1 a 100)\n",
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "SSd-n7TsObPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizamos\n",
        "for input_example, target_example in dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data: ', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwt86loIO3Ew",
        "outputId": "81cc4cdd-a43e-45ad-8a31-a5069ad11248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data:  '\\ufeffThe Project Gutenberg eBook of The Son of Tarzan\\r\\n    \\r\\nThis ebook is for the use of anyone anywher'\n",
            "Target data:  'The Project Gutenberg eBook of The Son of Tarzan\\r\\n    \\r\\nThis ebook is for the use of anyone anywhere'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imprimir dataset\n",
        "print (dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sS6s_VLoPSCB",
        "outputId": "e3391ac7-f35c-4687-b34e-fb496265ed8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int64, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#agrupar en batches\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUZRIbkGPiuS",
        "outputId": "8616d02e-6cdc-4c66-bbc4-c0a6a3f3ea40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construir modelo RNN"
      ],
      "metadata": {
        "id": "CiQZ_CevQAoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                batch_input_shape=[batch_size,None]),\n",
        "\n",
        "      tf.keras.layers.LSTM(rnn_units,\n",
        "                           return_sequences=True,\n",
        "                           stateful = True,\n",
        "                           recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "      tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim= 256\n",
        "rnn_units = 1024\n",
        "\n",
        "model = build_model(\n",
        "    vocab_size = vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size = BATCH_SIZE\n",
        ")"
      ],
      "metadata": {
        "id": "uCCdG2uZQCQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizar estructura\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKsclvjYypZ0",
        "outputId": "3e7d848f-2b36-4c93-b597-463fa97958ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (64, None, 256)           23296     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense (Dense)               (64, None, 91)            93275     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5363547 (20.46 MB)\n",
            "Trainable params: 5363547 (20.46 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Forma de input\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  print(\"Input: \", input_example_batch.shape, \"# (batch_size, lenght)\")\n",
        "  print(\"Target: \", target_example_batch.shape, \"# (batch_size, sequence_length)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW-eJDbfzNIH",
        "outputId": "6416b810-ed43-4102-c3e5-f9981e3b59a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  (64, 100) # (batch_size, lenght)\n",
            "Target:  (64, 100) # (batch_size, sequence_length)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Forma de salida\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(\"Prediction: \", example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbAXsYuDztDZ",
        "outputId": "ef77b466-a58b-4a24-fa1d-d08add263257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:  (64, 100, 91) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostar que el resultado es una distribucion, no un argmax\n",
        "\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices_characters = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "print(sampled_indices_characters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exs9IP990Rcx",
        "outputId": "faab42fb-3733-4e62-b867-e0ca2ce313b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[90 68 32 37 28 75 85  4 54 20 53 61 36 72 74 18 83 63 87 71 57 26 70  0\n",
            " 44 43 60 77 86 52 76 77  4 69 48 90 50 32 22 13 48 40 77 51 83 90 40 13\n",
            "  4 56 21 64 14  0 45 28 24 75 11 90 51 47 67 47  4 76 71 65 56 44 67 53\n",
            " 85 39 66  0 18 60 10 62 43 47 70 37  3 47 71 20 43 48 29 85 31 82 62 45\n",
            " 67 71 24  2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ENTRENAMIENTO"
      ],
      "metadata": {
        "id": "hByCt7iq0rOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "model.compile(optimizer='adam', loss=loss)\n"
      ],
      "metadata": {
        "id": "13WGBj8X0sDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_(epoch)\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True\n",
        ")"
      ],
      "metadata": {
        "id": "ZSqhYQKh2Mgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-yqaDcg1Q6l",
        "outputId": "84a88c69-efdc-424c-fdcf-376e6f6e7ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "85/85 [==============================] - 10s 79ms/step - loss: 2.8155\n",
            "Epoch 2/50\n",
            "85/85 [==============================] - 8s 72ms/step - loss: 2.1405\n",
            "Epoch 3/50\n",
            "85/85 [==============================] - 7s 73ms/step - loss: 1.8638\n",
            "Epoch 4/50\n",
            "85/85 [==============================] - 7s 69ms/step - loss: 1.6707\n",
            "Epoch 5/50\n",
            "85/85 [==============================] - 7s 70ms/step - loss: 1.5351\n",
            "Epoch 6/50\n",
            "85/85 [==============================] - 7s 71ms/step - loss: 1.4333\n",
            "Epoch 7/50\n",
            "85/85 [==============================] - 7s 71ms/step - loss: 1.3593\n",
            "Epoch 8/50\n",
            "85/85 [==============================] - 7s 73ms/step - loss: 1.3041\n",
            "Epoch 9/50\n",
            "85/85 [==============================] - 7s 73ms/step - loss: 1.2564\n",
            "Epoch 10/50\n",
            "85/85 [==============================] - 7s 74ms/step - loss: 1.2142\n",
            "Epoch 11/50\n",
            "85/85 [==============================] - 8s 75ms/step - loss: 1.1761\n",
            "Epoch 12/50\n",
            "85/85 [==============================] - 7s 76ms/step - loss: 1.1384\n",
            "Epoch 13/50\n",
            "85/85 [==============================] - 7s 75ms/step - loss: 1.1024\n",
            "Epoch 14/50\n",
            "85/85 [==============================] - 7s 78ms/step - loss: 1.0676\n",
            "Epoch 15/50\n",
            "85/85 [==============================] - 7s 78ms/step - loss: 1.0312\n",
            "Epoch 16/50\n",
            "85/85 [==============================] - 8s 79ms/step - loss: 0.9922\n",
            "Epoch 17/50\n",
            "85/85 [==============================] - 8s 79ms/step - loss: 0.9517\n",
            "Epoch 18/50\n",
            "85/85 [==============================] - 8s 79ms/step - loss: 0.9129\n",
            "Epoch 19/50\n",
            "85/85 [==============================] - 7s 77ms/step - loss: 0.8719\n",
            "Epoch 20/50\n",
            "85/85 [==============================] - 7s 76ms/step - loss: 0.8274\n",
            "Epoch 21/50\n",
            "85/85 [==============================] - 8s 76ms/step - loss: 0.7854\n",
            "Epoch 22/50\n",
            "85/85 [==============================] - 8s 79ms/step - loss: 0.7429\n",
            "Epoch 23/50\n",
            "85/85 [==============================] - 8s 79ms/step - loss: 0.7019\n",
            "Epoch 24/50\n",
            "85/85 [==============================] - 8s 79ms/step - loss: 0.6619\n",
            "Epoch 25/50\n",
            "85/85 [==============================] - 7s 78ms/step - loss: 0.6220\n",
            "Epoch 26/50\n",
            "85/85 [==============================] - 7s 77ms/step - loss: 0.5887\n",
            "Epoch 27/50\n",
            "85/85 [==============================] - 8s 75ms/step - loss: 0.5532\n",
            "Epoch 28/50\n",
            "85/85 [==============================] - 7s 76ms/step - loss: 0.5232\n",
            "Epoch 29/50\n",
            "85/85 [==============================] - 7s 77ms/step - loss: 0.4961\n",
            "Epoch 30/50\n",
            "85/85 [==============================] - 7s 77ms/step - loss: 0.4719\n",
            "Epoch 31/50\n",
            "85/85 [==============================] - 8s 77ms/step - loss: 0.4473\n",
            "Epoch 32/50\n",
            "85/85 [==============================] - 7s 78ms/step - loss: 0.4279\n",
            "Epoch 33/50\n",
            "85/85 [==============================] - 8s 79ms/step - loss: 0.4102\n",
            "Epoch 34/50\n",
            "85/85 [==============================] - 8s 78ms/step - loss: 0.3935\n",
            "Epoch 35/50\n",
            "85/85 [==============================] - 8s 79ms/step - loss: 0.3802\n",
            "Epoch 36/50\n",
            "85/85 [==============================] - 7s 76ms/step - loss: 0.3666\n",
            "Epoch 37/50\n",
            "85/85 [==============================] - 8s 76ms/step - loss: 0.3559\n",
            "Epoch 38/50\n",
            "85/85 [==============================] - 7s 76ms/step - loss: 0.3483\n",
            "Epoch 39/50\n",
            "85/85 [==============================] - 7s 77ms/step - loss: 0.3382\n",
            "Epoch 40/50\n",
            "85/85 [==============================] - 7s 78ms/step - loss: 0.3303\n",
            "Epoch 41/50\n",
            "85/85 [==============================] - 8s 78ms/step - loss: 0.3252\n",
            "Epoch 42/50\n",
            "85/85 [==============================] - 8s 79ms/step - loss: 0.3173\n",
            "Epoch 43/50\n",
            "85/85 [==============================] - 8s 79ms/step - loss: 0.3137\n",
            "Epoch 44/50\n",
            "85/85 [==============================] - 8s 78ms/step - loss: 0.3058\n",
            "Epoch 45/50\n",
            "85/85 [==============================] - 8s 77ms/step - loss: 0.3032\n",
            "Epoch 46/50\n",
            "85/85 [==============================] - 7s 77ms/step - loss: 0.2973\n",
            "Epoch 47/50\n",
            "85/85 [==============================] - 7s 77ms/step - loss: 0.2954\n",
            "Epoch 48/50\n",
            "85/85 [==============================] - 7s 77ms/step - loss: 0.2896\n",
            "Epoch 49/50\n",
            "85/85 [==============================] - 8s 76ms/step - loss: 0.2870\n",
            "Epoch 50/50\n",
            "85/85 [==============================] - 7s 77ms/step - loss: 0.2822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generacion de texto"
      ],
      "metadata": {
        "id": "K3se79_t9L_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "metadata": {
        "id": "RCqFtIqc9OQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string, temp):\n",
        "  num_generate = 500\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "\n",
        "  temperature = temp\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "\n",
        "    predictions = tf.squeeze(predictions,0)\n",
        "\n",
        "    predictions = predictions/temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    input_eval = tf.expand_dims([predicted_id],0)\n",
        "\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return(start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "Lbk-KF_v93lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"tarzan\", temp=0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywey-I4D_F6G",
        "outputId": "a29ae8b9-107f-459b-8014-96d344ca839a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tarzan king, for the boy wishes in which the\r\n",
            "photograph of a little girl upon the bed country where The Sheik held him back, and\r\n",
            "form the right with the handsome face, and there, for an angry\r\n",
            "relations to the north the Big Bwana and his black warriors clung tenaciously\r\n",
            "to the trail of the lesson attempted to analyse the relationship than that of them.\r\n",
            "\r\n",
            "Korak landed with the exclusion of the jungle. He would not have thought of himself at all; but the egotism of the house men—Mr. Moore recognized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"tarzan\", temp=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro0Zsvg9nJDx",
        "outputId": "bdbd21c1-3e0d-4e1e-92f8-2e3d2a3ecf69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tarzan’s wildsome them.\r\n",
            "\r\n",
            "Korak saw the man before him, turned back toward the\r\n",
            "village. Here was the boat thus day the beast’s hangings that had\r\n",
            "defeared him. Uniffed battle with the agility of a Cannot lorat\r\n",
            "Of London, where, he shouted to\r\n",
            "his captive that the blacks followed him, and\r\n",
            "this listening flight for the\r\n",
            "great Akut and at a dorge\r\n",
            "\r\n",
            "and and his little eyes because of his soul of the old wealok took him more\r\n",
            "of the clearing and developed in the direction of the thing that had been in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"son\", temp=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJZ1jcp-_UM9",
        "outputId": "e2a482c5-8049-41be-857e-b175a30a24b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "son on which she had tet her indicatory of the Swede.\r\n",
            "\r\n",
            "As the Hon. Morison laughed uneasily. He didn’t care to appear at a\r\n",
            "disadvantage before this giant and the\r\n",
            "yellow-greater of filthy dampered trump within his\r\n",
            "brd Baynes, and but the two\r\n",
            "halted fig an ungramment. If you do not agree to abide by all\r\n",
            "the adert for any mor the strangers.\r\n",
            "How he loved? She drew back in the enclosure a\r\n",
            "mighty north almost the coast of it; but I may so Lord Greystoke, please, Molerous\r\n",
            "my eater at home.”\r\n",
            "\r\n",
            "“\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"son\", temp=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01lFrxrInMIL",
        "outputId": "09741074-6a0e-4965-ccc4-6b8c9b96f750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "son.”\r\n",
            "\r\n",
            "Then he dragged him killingnesse-might little trademabls\r\n",
            "upon Jenssen. He through the timl? Lost nail yow; but that he epcive\r\n",
            "if she was!”\r\n",
            "\r\n",
            "It was liOked; to him k oSAkumeabl, phy dailty comp warm.\r\n",
            "\r\n",
            "AT TH[AR, the Mangani, who macked them\r\n",
            "Forgative Panlim hesitauld, as “but ah, Ge?,2” are camp forball\r\n",
            "hunting heret\r\n",
            "jungle mage—it,” he commanded. “Welitu puny or questions of the lad, and, MhoD\r\n",
            "All rided skrnow more\r\n",
            "ought them at knie, but AfCtibut is husce, troups, give him \r\n",
            "That\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"father\", temp=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE-rdd8X_Zbm",
        "outputId": "778226eb-b646-4423-a70f-2b98aac5a1a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "father,” angrmels\r\n",
            "\r\n",
            "My his own, and.\r\n",
            "\r\n",
            "“NDo,”) rash at no sign of dather she e.’Qwey’s faces of geather.”\r\n",
            "\r\n",
            "He gavela and cun help? Ing nazed and lowful Geeka whinded iFw/crossing\r\n",
            "in tivet, the For his Eku?”\r\n",
            "\r\n",
            "“NDa, Vo0 M8 zandly. But, some\r\n",
            "friend he e Proj O™n enemieff u™w\r\n",
            "cross/be, bo,” ald the Hon. Morison noticed n knew escape wit\r\n",
            "but the ape? As held\r\n",
            "Har\n",
            "Secr them—he tostipuls, dotelve it, after goasu, and princitatofF” and run to follow the is creeis\r\n",
            "vaduated d attacked them y\r\n",
            "slighte\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"son\", temp=0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSH5pvMmnQsy",
        "outputId": "d9820e4c-0c8f-43b0-d4d5-7fb0ce33c547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "son\r\n",
            "one of the music hall and see Ajax, with a length of ancient slave chain fastened at one end to an iron\r\n",
            "collar padlocked about her nose at the addres\r\n",
            "toward the North Baynes leaped their flying\r\n",
            "mounts through the breach in the palisade and were gone up the\r\n",
            "well-work, shortly as though it and what he had the chosurath and annively shribl, of cient and the two ponies. He\r\n",
            "had been with Malbihn for a year. The baboons continued to take her with\r\n",
            "him by force rather than stolen place a few fee\n"
          ]
        }
      ]
    }
  ]
}